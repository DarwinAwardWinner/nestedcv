% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/outercv.R
\name{outercv}
\alias{outercv}
\alias{outercv.default}
\alias{outercv.formula}
\title{Outer cross-validation of selected models}
\usage{
outercv(y, ...)

\method{outercv}{default}(
  y,
  x,
  model,
  filterFUN = NULL,
  filter_options = NULL,
  outer_method = c("cv", "LOOCV"),
  n_outer_folds = 10,
  cv.cores = 1,
  predict_type = "prob",
  ...
)

\method{outercv}{formula}(
  formula,
  data,
  model,
  outer_method = c("cv", "LOOCV"),
  n_outer_folds = 10,
  cv.cores = 1,
  ...
)
}
\arguments{
\item{y}{Response vector}

\item{...}{Optional arguments passed to the function specified by \code{model}.}

\item{x}{Matrix or data frame of predictors}

\item{model}{Model function to be fitted.}

\item{filterFUN}{Filter function, e.g. \link{ttest_filter} or \link{relieff_filter}.
Any function can be provided and is passed \code{y} and \code{x}. Must return a
character vector with names of filtered predictors. Not available if
\code{outercv} is called with a formula.}

\item{filter_options}{List of additional arguments passed to the filter
function specified by \code{filterFUN}.}

\item{outer_method}{String of either \code{"cv"} or \code{"LOOCV"} specifying whether
to do k-fold CV or leave one out CV (LOOCV) for the outer folds}

\item{n_outer_folds}{Number of outer CV folds}

\item{cv.cores}{Number of cores for parallel processing. Note this currently
uses \link[parallel:mclapply]{parallel::mclapply}.}

\item{predict_type}{Only used with binary classification. Calculation of ROC
AUC requires predicted class probabilities from fitted models. Most model
functions use syntax of the form \code{predict(..., type = "prob")}. However,
some models require a different \code{type} to be specified, which can be passed
to \code{predict()} via \code{predict_type}.}

\item{formula}{A formula describing the model to be fitted}

\item{data}{A matrix or data frame containing variables in the model.}
}
\value{
An object with S3 class "outercv"
\item{call}{the matched call}
\item{output}{Predictions on the left-out outer folds}
\item{outer_result}{List object of results from each outer fold containing
predictions on left-out outer folds, model result and number of filtered
predictors at each fold.}
\item{dimx}{vector of number of observations and number of predictors}
\item{outer_folds}{List of indices of outer training folds}
\item{final_fit}{Final fitted model on whole data}
\item{final_vars}{Column names of filtered predictors entering final model}
\item{roc}{ROC AUC for binary classification where available.}
\item{summary}{Overall performance summary. Accuracy and balanced accuracy
for classification. ROC AUC for binary classification. RMSE for
regression.}
}
\description{
This is a convenience function designed to use a single loop of
cross-validation to quickly evaluate performance of specific models (random
forest, naive Bayes, lm, glm) with fixed hyperparameters and no tuning. If
tuning of parameters on data is required, full nested CV with inner CV is
needed to tune model hyperparameters (see \link{nestcv.train}).
}
\details{
Some predictive model functions do not have an x & y interface. If the
function specified by \code{model} requires a formula, \code{x} & \code{y} will be merged
into a data.frame with \code{model()} called with a formula equivalent to
\code{y ~ .}.

An alternative method of tuning a single model with fixed parameters
is to use \link{nestcv.train} with \code{tuneGrid} set as a single row of a
data.frame. The parameters which are needed for a specific model can be
identified using \code{\link[caret:modelLookup]{caret::modelLookup()}}.

The formula method for \code{outercv} is not recommended with large data sets -
it is designed primarily for more basic models e.g. \code{lm()} and \code{glm()}.
Filtering is not available if \code{outercv} is called with a formula - use \code{x}
and \code{y} interface instead.

Note that in the case of \code{model = lm}, although additional arguments e.g.
\code{subset}, \code{weights}, \code{offset} are passed into the model function via
\code{"..."} the scoping is known to go wrong. Avoid using these arguments with
\code{model = lm}.
}
