% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nestcv.train.R
\name{nestcv.train}
\alias{nestcv.train}
\title{Nested CV for caret}
\usage{
nestcv.train(
  y,
  x,
  filterFUN = NULL,
  filter_options = NULL,
  n_outer_folds = 10,
  cores = 1,
  metric = ifelse(is.factor(y), "logLoss", "RMSE"),
  trControl = NULL,
  tuneGrid = NULL,
  savePredictions = FALSE,
  ...
)
}
\arguments{
\item{y}{Response vector. For classification this should be a factor.}

\item{x}{Matrix of predictors}

\item{filterFUN}{Filter function, e.g. \link{ttest_filter} or \link{relieff_filter}.
Any function can be provided and is passed \code{y} and \code{x}. Must return a
character vector with names of filtered predictors.}

\item{filter_options}{List of additional arguments passed to the filter
function specified by \code{filterFUN}.}

\item{n_outer_folds}{Number of outer CV folds}

\item{cores}{Number of cores for parallel processing. Note this currently
uses \code{parallel::mclapply}.}

\item{metric}{A string that specifies what summary metric will be used to
select the optimal model. By default, "logLoss" is used for classification
and "RMSE" is used for regression. Note this differs from the default setting
in caret which uses "Accuracy" for classification. See details.}

\item{trControl}{A list of values generated by the \code{caret} function
\link{trainControl}. This defines how inner CV training through \code{caret} is
performed. See http://topepo.github.io/caret/using-your-own-model-in-train.html.}

\item{tuneGrid}{Data frame of tuning values, see \link[caret:train]{caret::train}}

\item{savePredictions}{Indicates whether hold-out predictions for
each inner CV fold should be saved for ROC curves, accuracy etc
see \link[caret:trainControl]{caret::trainControl}.Set to \code{"final"} to capture predictions for inner
CV ROC.}

\item{...}{Arguments passed to \link[caret:train]{caret::train}}
}
\description{
Wrapper function for applying nested CV and predictor filtering followed by
training using \code{caret}.
}
\details{
Parallelisation is performed on the outer folds using \code{mclapply}.
For classification \code{metric} defaults to using 'logLoss' with the \code{trControl}
arguments \verb{classProbs = TRUE, summaryFunction = mnLogLoss}, rather than
'Accuracy' which is the default classification metric in \code{caret}. See
\link{trainControl}. LogLoss is arguably more consistent than Accuracy for tuning
parameters in datasets with small sample size.
}
\author{
Myles Lewis
}
