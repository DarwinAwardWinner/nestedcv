

#' Nested CV for caret
#' 
#' Wrapper function for applying nested CV and predictor filtering followed by 
#' training using `caret`.
#' 
#' @param y Response vector. For classification this should be a factor.
#' @param x Matrix of predictors
#' @param filterFUN Filter function, e.g. [ttest_filter] or [relieff_filter]. 
#' Any function can be provided and is passed `y` and `x`. Must return a 
#' character vector with names of filtered predictors.
#' @param filter_options List of additional arguments passed to the filter 
#' function specified by `filterFUN`.
#' @param n_outer_folds Number of outer CV folds
#' @param metric A string that specifies what summary metric will be used to 
#' select the optimal model. By default, "logLoss" is used for classification 
#' and "RMSE" is used for regression. Note this differs from the default setting 
#' in caret which uses "Accuracy" for classification. See details.
#' @param trControl A list of values generated by the `caret` function 
#' [trainControl]. This defines how inner CV training through `caret` is 
#' performed. See http://topepo.github.io/caret/using-your-own-model-in-train.html.
#' @param tuneGrid Data frame of tuning values, see [caret::train]
#' @param savePredictions Indicates whether hold-out predictions for 
#' each inner CV fold should be saved for ROC curves, accuracy etc
#' see [caret::trainControl].Set to `"final"` to capture predictions for inner 
#' CV ROC.
#' @param cores Number of cores for parallel processing. Note this currently 
#' uses `parallel::mclapply`.
#' @param ... Arguments passed to [caret::train]
#' @details Parallelisation is performed on the outer folds using `mclapply`. 
#' For classification `metric` defaults to using 'logLoss' with the `trControl` 
#' arguments `classProbs = TRUE, summaryFunction = mnLogLoss`, rather than 
#' 'Accuracy' which is the default classification metric in `caret`. See 
#' [trainControl]. LogLoss is arguably more consistent than Accuracy for tuning 
#' parameters in datasets with small sample size.
#' @author Myles Lewis
#' @importFrom caret createFolds train trainControl mnLogLoss confusionMatrix
#' defaultSummary
#' @importFrom data.table rbindlist
#' @importFrom parallel mclapply
#' @importFrom pROC roc
#' @importFrom stats predict setNames
#' @export
#' 
nestcv.train <- function(y, x,
                         filterFUN = NULL,
                         filter_options = NULL, 
                         n_outer_folds = 10,
                         cores = 1,
                         metric = ifelse(is.factor(y), "logLoss", "RMSE"),
                         trControl = NULL,
                         tuneGrid = NULL,
                         savePredictions = FALSE,
                         ...) {
  if (is.null(trControl)) {
    trControl <- if (is.factor(y)) {
      trainControl(method = "cv", 
                   number = 10,
                   classProbs = TRUE,
                   savePredictions = savePredictions,
                   summaryFunction = mnLogLoss)
    } else trainControl(method = "cv", 
                        number = 10,
                        savePredictions = savePredictions)
  }
  # switch off inner CV if tuneGrid is single row
  if (!is.null(tuneGrid)) {
    if (nrow(tuneGrid == 1)) trControl <- trainControl(method = "none", classProbs = TRUE)
  }
  outer_folds <- createFolds(y, k = n_outer_folds, returnTrain = TRUE)
  outer_res <- mclapply(1:n_outer_folds, function(i) {
    trainIndex <- outer_folds[[i]]
    filtx <- if (is.null(filterFUN)) x else {
      args <- list(y = y[trainIndex], x = x[trainIndex, ])
      args <- append(args, filter_options)
      fset <- do.call(filterFUN, args)
      x[, fset]
    }
    fit <- caret::train(x = filtx[trainIndex, ], y = y[trainIndex],
                        metric = metric,
                        trControl = trControl,
                        tuneGrid = tuneGrid, ...)
    predy <- predict(fit, newdata = filtx[-trainIndex, ], type = "raw")
    predyp <- predict(fit, newdata = filtx[-trainIndex, ], type = "prob")
    # note predyp has 2 columns
    
    preds <- data.frame(predy=predy, predyp=predyp[,2], testy=y[-trainIndex])
    rownames(preds) <- rownames(x[-trainIndex, ])
    ret <- list(preds = preds,
                fit = fit,
                nfilter = ncol(filtx))
    ret
  }, mc.cores = cores)
  predslist <- lapply(outer_res, '[[', 'preds')
  output <- data.table::rbindlist(predslist)
  output <- as.data.frame(output)
  caret.roc <- NULL
  if (is.factor(y)) {
    if (nlevels(y) == 2) {
      cm <- table(output$predy, output$testy)
      acc <- sum(diag(cm))/ sum(cm)
      ccm <- caret::confusionMatrix(cm)
      b_acc <- ccm$byClass[11]
      caret.roc <- pROC::roc(output$testy, output[, 2], direction = "<")
      auc <- caret.roc$auc
      summary <- setNames(c(auc, acc, b_acc), c("AUC", "Accuracy", "Bal_accuracy"))
    } else {
      # multinomial class
      cm <- table(output$predy, output$testy)
      acc <- sum(diag(cm))/ sum(cm)
      ccm <- caret::confusionMatrix(cm)
      b_acc <- ccm$byClass[11]
      summary <- setNames(c(acc, b_acc), c("Accuracy", "Bal_accuracy"))
    }
  } else {
    # regression
    df <- data.frame(obs = output$testy, pred = output$predy)
    summary <- caret::defaultSummary(df)
  }
  bestTunes <- lapply(outer_res, function(i) i$fit$bestTune)
  bestTunes <- as.data.frame(data.table::rbindlist(bestTunes))
  rownames(bestTunes) <- paste0('Fold', 1:n_outer_folds)
  finalTune <- colMeans(bestTunes)
  finalTune <- data.frame(as.list(finalTune))
  filtx <- if (is.null(filterFUN)) x else {
    args <- list(y = y, x = x)
    args <- append(args, filter_options)
    fset <- do.call(filterFUN, args)
    x[, fset]
  }
  fitControl <- trainControl(method = "none", classProbs = TRUE)
  final_fit <- caret::train(x = filtx, y = y, 
                            trControl = fitControl,
                            tuneGrid = finalTune, ...)
  
  out <- list(output = output,
              outer_result = outer_res,
              final_fit = final_fit,
              final_vars = colnames(filtx),
              roc = caret.roc,
              bestTunes = bestTunes,
              finalTune = finalTune,
              summary = summary)
  class(out) <- "nestcv.train"
  out
}


#' @method predict nestcv.train
#' @export
predict.nestcv.train <- function(object, newdata, ...) {
  if (any(!object$final_vars %in% colnames(newdata))) 
    stop("newdata is missing some predictors", call. = FALSE)
  predict(object$final_fit, newdata = newdata[, object$final_vars], ...)
}
